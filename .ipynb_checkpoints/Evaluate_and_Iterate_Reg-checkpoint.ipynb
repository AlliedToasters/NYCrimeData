{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Challenge: Evaluate and Iterate Regression Model</H1><br><br>\n",
    "This project uses the New York State crime statistics data for 2013, taken from <a href='https://ucr.fbi.gov/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/table-8/table-8-state-cuts/table_8_offenses_known_to_law_enforcement_new_york_by_city_2013.xls'>the FBI UCR repository</a>.<br><br>\n",
    "\n",
    "This challenge is a progression of <a href='https://github.com/AlliedToasters/NYCrimeData/blob/master/My_First_LinReg.ipynb'>my first linear regression model</a>. I evaluate the model with a variety of techniques and, based on the results of the evaluation, will try to improve it.<br><br>\n",
    "<H2>First Evaluation: Cross Validation</H2><br><br>\n",
    "Considering our number of data is in the low hundreds, I'll try cross validation with ten folds. I'll randomly sample the population, train the model on three folds, and see how it does on the fourth. I'll repeat this process four times, once for each fold.<br><br>\n",
    "Building the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "%matplotlib inline\n",
    "sns.set_context(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('clean_crime_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['PC_per_capita'], df['Burg_per_capita'] = df['Property crime']/df.Population, df['Burglary']/df.Population\n",
    "df['LT_per_capita'], df['MVT_per_capita'] = df['Larceny-theft']/df.Population, df['Motor vehicle theft']/df.Population\n",
    "\n",
    "df['cbrt_PCpc'] = np.cbrt(df['PC_per_capita'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['VCpc'] = df['Violent crime']/df.Population #Aggregated property crime per capita\n",
    "df['frthrt_VCpc'] = np.power(df['VCpc'], (1/4)) #Take the fourth root to get nice linear correlation to target var\n",
    "\n",
    "#Binary feature, tags if zero violent crime in city\n",
    "df['no_VC'] = np.where((df['Violent crime'] == 0), 1, 0)\n",
    "\n",
    "#Binary feature, tags if any murder reported in city\n",
    "df['has_Murd'] = np.where((df['Murder and nonnegligent manslaughter'] > 0), 1, 0)\n",
    "\n",
    "#Binary feature, tags if New York City. Obviously a unique data point.\n",
    "df['is_NYC'] = np.where((df.City == 'New York'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['known_arson'] = np.where((df['Arson3'].notnull()), df['Arson3'], 0)\n",
    "df['has_arson'] = np.where((df['Arson3'] > 0), 1, 0)\n",
    "ars = df[df['has_arson'] == 1]\n",
    "\n",
    "ars_regr = linear_model.LinearRegression()\n",
    "murds = ars['Murder and nonnegligent manslaughter'].values.reshape(-1, 1)\n",
    "arsn = ars.known_arson.values.reshape(-1, 1)\n",
    "ars_regr.fit(murds, arsn) #fit data\n",
    "ars_regr.score(murds, arsn)\n",
    "df['pred_arson'] = ars_regr.predict(df['Murder and nonnegligent manslaughter'].values.reshape(-1, 1)) #predict\n",
    "df['pred_arson'] = np.where((df['pred_arson'] < 0), 0, 1) #When regression gives negative values, set to zero\n",
    "df['est_arson'] = np.where((df['has_arson'] == 1), df['Arson3'], df['pred_arson']) \n",
    "#use real numbers where available.\n",
    "\n",
    "df['est_arson_per_capita'] = df['est_arson']/df.Population #per capita\n",
    "df['frthrt_ars_pc'] = np.power((df['est_arson_per_capita']), (1/4)) #And take a root transform to make things tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll write a function for performing the cross-validation which will return an R-squared value for each fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(data, train, target, folds=10):\n",
    "    \"\"\"Takes a pd.DataFrame, list of training variables, and a list of target variables.\n",
    "    Optional keyword argument folds specifies desired number of folds/holdout groups.\n",
    "    Does cross validation test with n number of folds and returns a list of Rsquared values\n",
    "    equal in length to the number of folds. Uses smf.ols for regression statistics.\n",
    "    \"\"\"\n",
    "    n = int(folds) #n tracks desired number of folds\n",
    "    folds = dict() #will track selected indices\n",
    "    inds = pd.Series(data.index) #use series type for .sample() method\n",
    "    selected = [] #will track indices already selected\n",
    "    mod = len(data)%n #handle remainder of len/folds\n",
    "    group_size = int((len(data)-mod)/n) #ensures proper integer group size\n",
    "    for fold in range(1, n+1):  #This loop selects random samples for each group\n",
    "        if fold == n:\n",
    "            group_size += mod #add remainder to last group\n",
    "        sample = inds[~inds.index.isin(selected)].sample(group_size) #excluded indices already selected\n",
    "        selected += list(sample)\n",
    "        name = 'sample_{}'.format(fold)\n",
    "        folds[name] = sample\n",
    "    scores = [] #This will be output\n",
    "    for sample in folds:\n",
    "        learn = data[~data.index.isin(folds[sample])][train] \n",
    "        targ = data[~data.index.isin(folds[sample])][target] #fit regression on all indices but fold\n",
    "        test_in = data[data.index.isin(folds[sample])][train]\n",
    "        test_targ = data[data.index.isin(folds[sample])][target] #holdout group for scoring\n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(learn, targ) #fit model\n",
    "        scores += [reg.score(test_in, test_targ)] #score model and add to 'scores'\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38188015615945314, 0.35495717402143978, 0.52828394300662573, 0.18887407937360723, 0.46521002693673863]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.383841\n",
       "std      0.128778\n",
       "min      0.188874\n",
       "25%      0.354957\n",
       "50%      0.381880\n",
       "75%      0.465210\n",
       "max      0.528284\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[df.City != \"New York\"]\n",
    "scores = cross_validate(data, ['frthrt_VCpc', 'no_VC', 'has_Murd', 'frthrt_ars_pc'], 'cbrt_PCpc', folds=5)\n",
    "print(scores)\n",
    "scr = pd.Series(scores)\n",
    "scr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see the Rsquared score vary quite a bit with a mean at .38 and standard deviation of .20. Next I build a similar function that uses smf.ols instead, allowing us to get some more regression statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_ols(data, train, target, folds=10):\n",
    "    \"\"\"Takes a pd.DataFrame, list of training variables, and a list of target variables.\n",
    "    Optional keyword argument folds specifies desired number of folds/holdout groups.\n",
    "    Does cross validation test with n number of folds and returns a list of Rsquared values\n",
    "    equal in length to the number of folds. Uses smf.ols for regression statistics.\n",
    "    \"\"\"\n",
    "    n = int(folds) #n tracks desired number of folds\n",
    "    folds = dict() #will track selected indices\n",
    "    inds = pd.Series(data.index) #use series type for .sample() method\n",
    "    selected = [] #will track indices already selected\n",
    "    mod = len(data)%n #handle remainder of len/folds\n",
    "    group_size = int((len(data)-mod)/n) #ensures proper integer group size\n",
    "    for fold in range(1, n+1):  #This loop selects random samples for each group\n",
    "        if fold == n:\n",
    "            group_size += mod #add remainder to last group\n",
    "        sample = inds[~inds.index.isin(selected)].sample(group_size) #excluded indices already selected\n",
    "        selected += list(sample)\n",
    "        name = 'sample_{}'.format(fold)\n",
    "        folds[name] = sample\n",
    "    scores = [] #This will be output\n",
    "    for sample in folds:\n",
    "        learn = data[~data.index.isin(folds[sample])]\n",
    "        test_set = data[data.index.isin(folds[sample])]\n",
    "        formula = target + ' ~ '\n",
    "        for feature in train:\n",
    "            formula += feature + '+'\n",
    "        formula = formula[:-1]\n",
    "        reg = smf.ols(formula=formula, data=learn).fit() #fit model\n",
    "        print('p values:', reg.pvalues)\n",
    "        print('rsquared', reg.rsquared)\n",
    "        print('confidence intervals', reg.conf_int())\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p values: Intercept        9.024463e-07\n",
      "frthrt_VCpc      1.482496e-11\n",
      "no_VC            8.626103e-03\n",
      "has_Murd         2.235821e-01\n",
      "frthrt_ars_pc    3.351317e-01\n",
      "dtype: float64\n",
      "rsquared 0.371927440845\n",
      "confidence intervals                       0         1\n",
      "Intercept      0.079796  0.180570\n",
      "frthrt_VCpc    0.586923  1.026727\n",
      "no_VC          0.017659  0.119675\n",
      "has_Murd      -0.047712  0.011236\n",
      "frthrt_ars_pc -0.506036  0.173374\n",
      "p values: Intercept        1.770614e-09\n",
      "frthrt_VCpc      4.424274e-13\n",
      "no_VC            5.545002e-03\n",
      "has_Murd         9.369582e-01\n",
      "frthrt_ars_pc    3.586411e-01\n",
      "dtype: float64\n",
      "rsquared 0.453915455554\n",
      "confidence intervals                       0         1\n",
      "Intercept      0.097083  0.184339\n",
      "frthrt_VCpc    0.573556  0.958388\n",
      "no_VC          0.018398  0.105324\n",
      "has_Murd      -0.025469  0.027598\n",
      "frthrt_ars_pc -0.437220  0.159155\n"
     ]
    }
   ],
   "source": [
    "data = df[df.City != \"New York\"]\n",
    "scores = cross_validate_ols(data, ['frthrt_VCpc', 'no_VC', 'has_Murd', 'frthrt_ars_pc'], 'cbrt_PCpc', folds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see pretty consistently that two features have high p-values and contain zero within their confidence intervals: has_Murd and frthrt_ars_pc. We should probably reject those features. Maybe without them our r-squared values will be more consistent.<br><br>\n",
    "<H2>Iterated Model: Only Statistically Significant Features</H2><br><br>\n",
    "The next iteration of this model retains only the two statistically significant features from the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49618995733012172, 0.37269264107340128, 0.43878644935299116, 0.28896334393468093, 0.43645233329127275]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.406617\n",
       "std      0.078965\n",
       "min      0.288963\n",
       "25%      0.372693\n",
       "50%      0.436452\n",
       "75%      0.438786\n",
       "max      0.496190\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(data, ['frthrt_VCpc', 'no_VC'], 'cbrt_PCpc', folds=5)\n",
    "print(scores)\n",
    "scr = pd.Series(scores)\n",
    "scr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to help, reducing the variance in r-squared scores while keeping the mean roughly unchanged.<br><br>\n",
    "<H2>Validating Against Other Data Sets</H2><br><br>\n",
    "I'd like to see how my model does on other data sets. Before doing so, I'll generalize the \"NYC\" feature for any major cities by using a population size cutoff. We'll set it at any city with a population of 1,000,000 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['is_big'] = np.where((df.Population > 500000), 1, 0)\n",
    "\n",
    "co_data = pd.read_excel('CO_crime_2013.xlsx') #Using Colorado, where I lived in 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "co_data['no_VC'] = np.where((co_data['Violent\\ncrime'] == 0), 1, 0)\n",
    "co_data['VCpc'] = co_data['Violent\\ncrime']/co_data.Population\n",
    "co_data['frthrt_VCpc'] = np.power(co_data.VCpc, (1/4))\n",
    "co_data['is_big'] = np.where((co_data.Population > 1000000), 1, 0) \n",
    "co_data['PCpc'] = co_data['Property\\ncrime']/co_data.Population\n",
    "co_data['cbrt_PCpc'] = np.cbrt(co_data.PCpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_reg = linear_model.LinearRegression()\n",
    "my_reg.fit(df[['frthrt_VCpc', 'no_VC']], df.cbrt_PCpc) #fit to NY 2013 data, 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26091150905400362"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_reg.score(co_data[['frthrt_VCpc', 'no_VC']], co_data.cbrt_PCpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This poor rsquared score suggests my model does not do well in Colorado, which is probably indicative of other states as well.<br><br>\n",
    "Let's see how well it does within New York State and take a look at the 2014 crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2014 = pd.read_excel('NY_crime_2014.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2014['no_VC'] = np.where((df_2014['Violent\\ncrime'] == 0), 1, 0)\n",
    "df_2014['VCpc'] = df_2014['Violent\\ncrime']/df_2014.Population\n",
    "df_2014['frthrt_VCpc'] = np.power(df_2014.VCpc, (1/4))\n",
    "df_2014['is_big'] = np.where((df_2014.Population > 1000000), 1, 0)\n",
    "df_2014['PCpc'] = df_2014['Property\\ncrime']/df_2014.Population\n",
    "df_2014['cbrt_PCpc'] = np.cbrt(df_2014.PCpc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29267855291214473"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_reg.score(df_2014[df_2014.cbrt_PCpc.notnull()][['frthrt_VCpc', 'no_VC']], df_2014[df_2014.cbrt_PCpc.notnull()].cbrt_PCpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rsquared score is a little better than that of Colorado 2013 but still not great. This may mean that my model is overfitting to its training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Conclusion</H2><br><br>\n",
    "After evaluating my model, I found that two of my features were statistically insignificant. I iterated my regression by retraining without those two features. The new model stil struggles to make accurate predictions on other data sets, suggesting some overfitting.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
